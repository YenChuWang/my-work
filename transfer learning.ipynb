{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers for FNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "# Layers for CNN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Data Preprocessing\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入資料集--cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train0), (x_test, y_test0) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 10\n",
    "(X_train, y_train0), (X_test, y_test0) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the range of featurs\n",
    "X_train = X_train / X_train.max()\n",
    "X_test = X_test / X_test.max()\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train0, 10)\n",
    "y_test = to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(X_train.shape[0])\n",
    "X_sample = X_train[idx]\n",
    "y_sample = y_train0[idx].squeeze()\n",
    "\n",
    "plt.imshow(X_sample)\n",
    "plt.title(name_list[y_sample])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers = [Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'),\n",
    "           MaxPool2D(),\n",
    "           Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "           MaxPool2D(),\n",
    "           Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "           GlobalAveragePooling2D()]\n",
    "\n",
    "FC_layers = [Dense(units=256, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_25  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 401,418\n",
      "Trainable params: 401,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential(CNN_layers+FC_layers)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 264s 5ms/sample - loss: 1.5872 - categorical_accuracy: 0.4546 - val_loss: 1.1956 - val_categorical_accuracy: 0.5745\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 205s 4ms/sample - loss: 1.0727 - categorical_accuracy: 0.6210 - val_loss: 0.9996 - val_categorical_accuracy: 0.6382\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 206s 4ms/sample - loss: 0.8827 - categorical_accuracy: 0.6910 - val_loss: 0.8479 - val_categorical_accuracy: 0.7033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e3c9a37ac8>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, batch_size=32, epochs=3,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "(u_train, v_train), (u_test, v_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_list = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train = u_train.reshape(60000, 28, 28, 1) / 255\n",
    "u_test = u_test.reshape(10000, 28, 28, 1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_train = to_categorical(v_train, 10)\n",
    "v_test = to_categorical(v_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers_2= [Conv2D(16, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "              GlobalAveragePooling2D()]\n",
    "FC_layers = [Dense(units=256, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_60 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_27  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 42,506\n",
      "Trainable params: 23,296\n",
      "Non-trainable params: 19,210\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential(CNN_layers_2+FC_layers)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in FC_layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 52s 858us/sample - loss: 0.5287 - categorical_accuracy: 0.8128 - val_loss: 0.5156 - val_categorical_accuracy: 0.8202\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 37s 624us/sample - loss: 0.4922 - categorical_accuracy: 0.8258 - val_loss: 0.4835 - val_categorical_accuracy: 0.8291\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 39s 646us/sample - loss: 0.4639 - categorical_accuracy: 0.8367 - val_loss: 0.5117 - val_categorical_accuracy: 0.8174\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 37s 620us/sample - loss: 0.4405 - categorical_accuracy: 0.8449 - val_loss: 0.4524 - val_categorical_accuracy: 0.8408\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 38s 640us/sample - loss: 0.4229 - categorical_accuracy: 0.8505 - val_loss: 0.4647 - val_categorical_accuracy: 0.8368\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 38s 635us/sample - loss: 0.4051 - categorical_accuracy: 0.8575 - val_loss: 0.4088 - val_categorical_accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 38s 636us/sample - loss: 0.3894 - categorical_accuracy: 0.8633 - val_loss: 0.4307 - val_categorical_accuracy: 0.8526\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 39s 655us/sample - loss: 0.3743 - categorical_accuracy: 0.8679 - val_loss: 0.4026 - val_categorical_accuracy: 0.8579\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 38s 637us/sample - loss: 0.3637 - categorical_accuracy: 0.8723 - val_loss: 0.4041 - val_categorical_accuracy: 0.8573\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 38s 631us/sample - loss: 0.3530 - categorical_accuracy: 0.8760 - val_loss: 0.3948 - val_categorical_accuracy: 0.8546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e3b24bbc88>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(u_train, v_train, batch_size=32, epochs=10,validation_data=(u_test, v_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 15s 255us/sample - loss: 0.3567 - categorical_accuracy: 0.8712\n",
      "10000/10000 [==============================] - 2s 237us/sample - loss: 0.3948 - categorical_accuracy: 0.8546\n",
      "Train Accuracy: 87.12499737739563\n",
      "Test Accuracy: 85.46000123023987\n"
     ]
    }
   ],
   "source": [
    "score_train = model2.evaluate(u_train, v_train)\n",
    "score_test = model2.evaluate(u_test, v_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
